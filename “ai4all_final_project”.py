# -*- coding: utf-8 -*-
"""“AI4ALL Final Project”

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/14yYjMRM8lfYzR2FrtVBlrjrvhMSYxx0b

Research Question: How do animal population densities change in different locations?
"""

from google.colab import drive
drive.mount('/content/drive')

zip_path = "'/content/drive/MyDrive/2022AI4ALL/5000images.zip'"
!cp {zip_path} .
!unzip -q 5000images.zip
!rm 5000images.zip

# First load necessary libraries
import json
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from collections import Counter

# Define paths to the images and the annotations
datadir = '5000images'

# Load the annotation file and explore what information is available
annotations = json.load(open("/content/drive/MyDrive/2022AI4ALL/5000_images_annotations.json"))

# Let's create a dictionary that maps category id (0-22) to category name
origid_to_name = {}
for i in range(len(annotations['categories'])):
    origid_to_name[annotations['categories'][i]['id']] = annotations['categories'][i]['name']

# Let's reformat the image labels so that they are easier to work with.
# Specifically, create a dictionary that maps image id to category name.
image_to_categoryname = {}
for i in range(len(annotations['images'])):
    
    # Get image id, category id, and category name of the i-th image
    image_id = annotations['images'][i]['id']
    category_id = annotations['annotations'][i]['category_id']
    category_name = origid_to_name[category_id]

    # Add entry to the labels dictionary
    if category_name in ['opossum', 'coyote', 'squirrel', 'deer', 'cat']:
        image_to_categoryname[image_id] = category_name

# Create a dictionary that maps category names to new category ids
name_to_newid = {'deer': 0, 'opossum': 1, 'coyote': 2, 'squirrel': 3, 'cat': 4}
newid_to_name = dict((y,x) for x,y in name_to_newid.items())
print('name_to_newid:', name_to_newid)
print('newid_to_name:', newid_to_name)

np.random.seed(123)
selected = []
for category_name in ['opossum', 'coyote', 'squirrel', 'deer', 'cat']:
    ids = [image_id for image_id in image_to_categoryname.keys() if image_to_categoryname[image_id]==category_name]
    # ^^ https://stackoverflow.com/questions/6981717/pythonic-way-to-combine-for-loop-and-if-statement
    selected.append(np.array(ids))
selected = np.stack(selected).flatten()

# Create a dictionary that mapss image id to a new category id
image_to_categoryid = {}
for image_id in selected:
    category_name = image_to_categoryname[image_id]    
    image_to_categoryid[image_id] = name_to_newid[category_name]

print(annotations['images'])
# Create a dictionary that maps image id to location id.
image_to_location = {}
for i in range(len(annotations['images'])):
    # Get image id, category id, and category name of the i-th image
    image_id = annotations['images'][i]['id']
    location_id = annotations['images'][i]['location']
    image_to_location[image_id] = location_id

images = np.array(list(image_to_categoryid.keys()))
locations = np.array(list(image_to_location.values()))
print(locations)
categories = np.array(list(image_to_categoryid.values()))

def split_by_location(dataset, locationid):
  selected = (locations == locationid)
  #print(train_selected)
  return dataset[selected]

X_train = split_by_location(images, 1)
print(X_train.shape)
X_test = split_by_location(images, 2)
print(X_test)

y_train = split_by_location(categories, 1)
y_test = split_by_location(categories, 2)

def split_by_animals(images, animals, animalskey):
  selected = []
  #print(len(dataset))
  for i in range(len(animals)):
    if(animals[i] in animalskey):
      selected.append(True)
    else:
      selected.append(False)
  #print(selected)
  return selected

select = split_by_animals(X_test, y_test, y_train)
X_test = X_test[select]
y_test = y_test[select]
print(y_test)

# resizing image
img_size = 28
def resize_image(img):
    resized = np.array(img.resize((img_size, img_size)))
    return resized

X_train_images = []
for image_id in X_train:
    img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
    transformed_image = resize_image(img)
    X_train_images.append(transformed_image)
X_train_images = np.stack(X_train_images)  
print('X_train_images', X_train_images.shape)

X_test_images = []

for image_id in X_test:
  img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
  transformed_image = resize_image(img)

  X_test_images.append(transformed_image)
X_test_images = np.stack(X_test_images)

from sklearn.linear_model import LogisticRegression
LR_images = LogisticRegression(max_iter=300)

size = X_train_images.shape[0]
print(y_train.shape)
LR_images.fit(X_train_images.reshape(size, -1), y_train)

# Now predict labels for the validation set
predictions = LR_images.predict(X_test_images.reshape(X_test_images.shape[0], -1))

# test for accuracy
from sklearn.metrics import accuracy_score
score = accuracy_score(predictions, y_test)

print(score)

def getlocationaccuracyLR(loc1, loc2):
    X_train = split_by_location(images, loc1)
    X_test = split_by_location(images, loc2)
    y_train = split_by_location(categories, loc1)
    y_test = split_by_location(categories, loc2)

    select = split_by_animals(X_test, y_test, y_train)
    X_test = X_test[select]
    y_test = y_test[select]
    

    X_train_images = []
    for image_id in X_train:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_train_images.append(transformed_image)
    
    X_train_images = np.stack(X_train_images) 

    X_test_images = []
    
    for image_id in X_test:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_test_images.append(transformed_image)
    
    X_test_images = np.stack(X_test_images)
    
    LR_images = LogisticRegression(max_iter=300)

    size = X_train_images.shape[0]
    LR_images.fit(X_train_images.reshape(size, -1), y_train)

    predictions = LR_images.predict(X_test_images.reshape(X_test_images.shape[0], -1))
    score = accuracy_score(predictions, y_test)

    return score

# Import the default K-Nearest Neighbors classifier

import matplotlib.pyplot as plt
from sklearn import datasets, neighbors

def getlocationaccuracyKNN(loc1, loc2):
    X_train = split_by_location(images, loc1)
    X_test = split_by_location(images, loc2)
    y_train = split_by_location(categories, loc1)
    y_test = split_by_location(categories, loc2)

    select = split_by_animals(X_test, y_test, y_train)
    X_test = X_test[select]
    y_test = y_test[select]
    

    X_train_images = []
    for image_id in X_train:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_train_images.append(transformed_image)
    
    X_train_images = np.stack(X_train_images) 

    X_test_images = []
    
    for image_id in X_test:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_test_images.append(transformed_image)
    
    X_test_images = np.stack(X_test_images)
    
    knn = neighbors.KNeighborsClassifier(n_neighbors=5)
    
    # Train the classifer
    knn.fit(X_train_images.reshape(X_train_images.shape[0],-1), y_train)
    
    # Compute the score (mean accuracy) on test set
    
    score = knn.score(X_test_images.reshape(X_test_images.shape[0], -1), y_test)
    
    return score

uniquelocations = np.unique(locations)

#Import Libraries

from sklearn.model_selection import train_test_split
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import confusion_matrix
import matplotlib.pyplot as plt

#Get location accuracy
def getlocationaccuracyNN(loc1, loc2):
    X_train = split_by_location(images, loc1)
    X_test = split_by_location(images, loc2)
    y_train = split_by_location(categories, loc1)
    y_test = split_by_location(categories, loc2)

    select = split_by_animals(X_test, y_test, y_train)
    X_test = X_test[select]
    y_test = y_test[select]
    

    X_train_images = []
    for image_id in X_train:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_train_images.append(transformed_image)
    
    X_train_images = np.stack(X_train_images) 

    X_test_images = []
    
    for image_id in X_test:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_test_images.append(transformed_image)
    
    X_test_images = np.stack(X_test_images)

#Apply MLPClassifier 
    NN_images = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1, max_iter=1000)                                  
    NN_images.fit(X_train_images.reshape(X_train_images.shape[0], -1), y_train)

#Calculating Scores
    Train_score = NN_images.score(X_train_images.reshape(X_train_images.shape[0], -1), y_train)
    Test_score = NN_images.score(X_test_images.reshape(X_test_images.shape[0], -1), y_test)
    print(Train_score)
    print(Test_score)

# Examine the loss curve   
    NN_images.fit(X_train_images.reshape([X_train_images.shape[0],-1]), y_train) 
    loss_values = NN_images.loss_curve_
    plt.plot(loss_values)
    plt.show()


    return Test_score

getlocationaccuracyNN(1, 2)

#Create neural network
from sklearn.neural_network import MLPClassifier
NN_images = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1, max_iter=1000)

# Examine the loss curve
NN_images.fit(X_train_images.reshape([3000,-1]), y_train) 
loss_values = NN_images.loss_curve_
plt.plot(loss_values)
plt.show()

# Get the trained model's predictions for the validation images
predictions = NN_images.predict(X_test_images.reshape((X_test_images.shape[0], -1)))
score = np.mean(predictions == y_test)

# Create and interpret the confusion matrix
#confusion_matrix(y_val, pred_val, labels=[0, 1, 2, 3, 4])


print(score)

print(uniquelocations)

def getaverageaccuracyLR(location):
  totalscore = 0
  count = 0

  for i in range(10):
    if(uniquelocations[i] != location):
      count += 1
      totalscore += getlocationaccuracyLR(location, uniquelocations[i])
      #print("Accuracy at Location", i, "is", getlocationaccuracyLR(location, uniquelocations[i]))
  
  return totalscore/count

def getaverageaccuracyKNN(location):
  totalscore = 0
  count = 0

  for i in range(10):
    if(uniquelocations[i] != location):
      count += 1
      totalscore += getlocationaccuracyKNN(location, uniquelocations[i])
      #print("Accuracy at Location", i, "is", getlocationaccuracyKNN(location, uniquelocations[i]))
  
  return totalscore/count

def getaverageaccuracyNN(location):
  totalscore = 0
  count = 0

  for i in range(10):
    if(uniquelocations[i] != location):
      count += 1
      totalscore += getlocationaccuracyNN(location, uniquelocations[i])
      #print("Accuracy at Location", i, "is", getlocationaccuracyNN(location, uniquelocations[i]))
  
  return totalscore/count

def bestaccuracyLR():
  best = 0
  bestloc = -1
  for i in range(10):
    accuracy = getaverageaccuracyLR(uniquelocations[i])
    if accuracy > best:
      best = accuracy
      bestloc = i
  
  print("Location", bestloc, "has the highest accuracy of", best)
  return best

def bestaccuracyKNN():
  best = 0
  bestloc = -1
  for i in range(10):
    accuracy = getaverageaccuracyKNN(uniquelocations[i])
    if accuracy > best:
      best = accuracy
      bestloc = i
  
  print("Location", bestloc, "has the highest accuracy of", best)
  return best

def bestaccuracyNN():
  best = 0
  bestloc = -1
  for i in range(10):
    accuracy = getaverageaccuracyNN(uniquelocations[i])
    if accuracy > best:
      best = accuracy
      bestloc = i
  
  print("Location", bestloc, "has the highest accuracy of", best)
  return best

bestaccuracyLR()
bestaccuracyNN()
bestaccuracyKNN()

"""Research Question: How do animal population densities change in different locations?"""

from google.colab import drive
drive.mount('/content/drive')

zip_path = "'/content/drive/MyDrive/Princeton AI4ALL/Day 6/5000images.zip'"
!cp {zip_path} .
!unzip -q 5000images.zip
!rm 5000images.zip

# First load necessary libraries
import json
import numpy as np
import matplotlib.pyplot as plt
from PIL import Image
from collections import Counter

# Define paths to the images and the annotations
datadir = '5000images'

# Load the annotation file and explore what information is available
annotations = json.load(open("/content/drive/MyDrive/Princeton AI4ALL/Day 6/5000_images_annotations.json"))

# Let's create a dictionary that maps category id (0-22) to category name
origid_to_name = {}
for i in range(len(annotations['categories'])):
    origid_to_name[annotations['categories'][i]['id']] = annotations['categories'][i]['name']

# Let's reformat the image labels so that they are easier to work with.
# Specifically, create a dictionary that maps image id to category name.
image_to_categoryname = {}
for i in range(len(annotations['images'])):
    
    # Get image id, category id, and category name of the i-th image
    image_id = annotations['images'][i]['id']
    category_id = annotations['annotations'][i]['category_id']
    category_name = origid_to_name[category_id]

    # Add entry to the labels dictionary
    if category_name in ['opossum', 'coyote', 'squirrel', 'deer', 'cat']:
        image_to_categoryname[image_id] = category_name

# Create a dictionary that maps category names to new category ids
name_to_newid = {'deer': 0, 'opossum': 1, 'coyote': 2, 'squirrel': 3, 'cat': 4}
newid_to_name = dict((y,x) for x,y in name_to_newid.items())
print('name_to_newid:', name_to_newid)
print('newid_to_name:', newid_to_name)

np.random.seed(123)
selected = []
for category_name in ['opossum', 'coyote', 'squirrel', 'deer', 'cat']:
    ids = [image_id for image_id in image_to_categoryname.keys() if image_to_categoryname[image_id]==category_name]
    # ^^ https://stackoverflow.com/questions/6981717/pythonic-way-to-combine-for-loop-and-if-statement
    selected.append(np.array(ids))
selected = np.stack(selected).flatten()

# Create a dictionary that mapss image id to a new category id
image_to_categoryid = {}
for image_id in selected:
    category_name = image_to_categoryname[image_id]    
    image_to_categoryid[image_id] = name_to_newid[category_name]

print(annotations['images'])
# Create a dictionary that maps image id to location id.
image_to_location = {}
for i in range(len(annotations['images'])):
    # Get image id, category id, and category name of the i-th image
    image_id = annotations['images'][i]['id']
    location_id = annotations['images'][i]['location']
    image_to_location[image_id] = location_id

images = np.array(list(image_to_categoryid.keys()))
locations = np.array(list(image_to_location.values()))
print(locations)
categories = np.array(list(image_to_categoryid.values()))

def split_by_location(dataset, locationid):
  selected = (locations == locationid)
  #print(train_selected)
  return dataset[selected]

X_train = split_by_location(images, 1)
print(X_train.shape)
X_test = split_by_location(images, 2)
print(X_test)

y_train = split_by_location(categories, 1)
y_test = split_by_location(categories, 2)

def split_by_animals(images, animals, animalskey):
  selected = []
  #print(len(dataset))
  for i in range(len(animals)):
    if(animals[i] in animalskey):
      selected.append(True)
    else:
      selected.append(False)
  #print(selected)
  return selected

select = split_by_animals(X_test, y_test, y_train)
X_test = X_test[select]
y_test = y_test[select]
print(y_test)

# resizing image
img_size = 28
def resize_image(img):
    resized = np.array(img.resize((img_size, img_size)))
    return resized

X_train_images = []
for image_id in X_train:
    img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
    transformed_image = resize_image(img)
    X_train_images.append(transformed_image)
X_train_images = np.stack(X_train_images)  
print('X_train_images', X_train_images.shape)

X_test_images = []

for image_id in X_test:
  img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
  transformed_image = resize_image(img)

  X_test_images.append(transformed_image)
X_test_images = np.stack(X_test_images)

from sklearn.linear_model import LogisticRegression
LR_images = LogisticRegression(max_iter=300)

size = X_train_images.shape[0]
print(y_train.shape)
LR_images.fit(X_train_images.reshape(size, -1), y_train)

# Now predict labels for the validation set
predictions = LR_images.predict(X_test_images.reshape(X_test_images.shape[0], -1))

# test for accuracy
from sklearn.metrics import accuracy_score
score = accuracy_score(predictions, y_test)

print(score)

def getlocationaccuracyLR(loc1, loc2):
    X_train = split_by_location(images, loc1)
    X_test = split_by_location(images, loc2)
    y_train = split_by_location(categories, loc1)
    y_test = split_by_location(categories, loc2)

    select = split_by_animals(X_test, y_test, y_train)
    X_test = X_test[select]
    y_test = y_test[select]
    

    X_train_images = []
    for image_id in X_train:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_train_images.append(transformed_image)
    
    X_train_images = np.stack(X_train_images) 

    X_test_images = []
    
    for image_id in X_test:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_test_images.append(transformed_image)
    
    X_test_images = np.stack(X_test_images)
    
    LR_images = LogisticRegression(max_iter=300)

    size = X_train_images.shape[0]
    LR_images.fit(X_train_images.reshape(size, -1), y_train)

    predictions = LR_images.predict(X_test_images.reshape(X_test_images.shape[0], -1))
    score = accuracy_score(predictions, y_test)

    return score

# Import the default K-Nearest Neighbors classifier

import matplotlib.pyplot as plt
from sklearn import datasets, neighbors

def getlocationaccuracyKNN(loc1, loc2):
    X_train = split_by_location(images, loc1)
    X_test = split_by_location(images, loc2)
    y_train = split_by_location(categories, loc1)
    y_test = split_by_location(categories, loc2)

    select = split_by_animals(X_test, y_test, y_train)
    X_test = X_test[select]
    y_test = y_test[select]
    

    X_train_images = []
    for image_id in X_train:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_train_images.append(transformed_image)
    
    X_train_images = np.stack(X_train_images) 

    X_test_images = []
    
    for image_id in X_test:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_test_images.append(transformed_image)
    
    X_test_images = np.stack(X_test_images)
    
    knn = neighbors.KNeighborsClassifier(n_neighbors=2)
    
    # Train the classifer
    knn.fit(X_train_images.reshape(X_train_images.shape[0],-1), y_train)
    
    # Compute the score (mean accuracy) on test set
    
    score = knn.score(X_test_images.reshape(X_test_images.shape[0], -1), y_test)
    
    return score

uniquelocations = np.unique(locations)

#Create neural network
from sklearn.neural_network import MLPClassifier
NN_images = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1, max_iter=1000)

def getlocationaccuracyNN(loc1, loc2):
    X_train = split_by_location(images, loc1)
    X_test = split_by_location(images, loc2)
    y_train = split_by_location(categories, loc1)
    y_test = split_by_location(categories, loc2)

    select = split_by_animals(X_test, y_test, y_train)
    X_test = X_test[select]
    y_test = y_test[select]
    

    X_train_images = []
    for image_id in X_train:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_train_images.append(transformed_image)
    
    X_train_images = np.stack(X_train_images) 

    X_test_images = []
    
    for image_id in X_test:
      img = Image.open('{}/{}.jpg'.format(datadir, image_id)).convert('RGB')
      transformed_image = resize_image(img)
      X_test_images.append(transformed_image)
    
    X_test_images = np.stack(X_test_images)
    
    NN_images = MLPClassifier(solver='adam', alpha=1e-5, hidden_layer_sizes=(100, 100), random_state=1, max_iter=1000)
    
    # Train
    NN_images.fit(X_train_images.reshape([X_train_images.shape[0],-1]), y_train) 

    # Get the trained model's predictions for the validation images
    predictions = NN_images.predict(X_test_images.reshape((X_test_images.shape[0], -1)))
    score = np.mean(predictions == y_test)  
    return score

print(uniquelocations)

def getaverageaccuracyLR(location):
  totalscore = 0
  count = 0

  for i in range(10):
    if(uniquelocations[i] != location):
      count += 1
      totalscore += getlocationaccuracyLR(location, uniquelocations[i])
      print("Accuracy at Location", i, "is", getlocationaccuracyLR(location, uniquelocations[i]))
  
  return totalscore/count

def getaverageaccuracyKNN(location):
  totalscore = 0
  count = 0

  for i in range(10):
    if(uniquelocations[i] != location):
      count += 1
      totalscore += getlocationaccuracyKNN(location, uniquelocations[i])
      print("Accuracy at Location", i, "is", getlocationaccuracyKNN(location, uniquelocations[i]))
  
  return totalscore/count

getaverageaccuracyKNN(1)

def getaverageaccuracyNN(location):
  totalscore = 0
  count = 0

  for i in range(10):
    if(uniquelocations[i] != location):
      count += 1
      totalscore += getlocationaccuracyNN(location, uniquelocations[i])
      print("Accuracy at Location", i, "is", getlocationaccuracyNN(location, uniquelocations[i]))
  
  return totalscore/count

def bestaccuracyLR():
  best = 0
  bestloc = -1
  for i in range(10):
    accuracy = getaverageaccuracyLR(uniquelocations[i])
    if accuracy > best:
      best = accuracy
      bestloc = i

  print("Location", bestloc, "has the highest accuracy of", best)
  return best

def bestaccuracyKNN():
  best = 0
  bestloc = -1
  for i in range(10):
    accuracy = getaverageaccuracyKNN(uniquelocations[i])
    if accuracy > best:
      best = accuracy
      bestloc = i
  
  print("Location", bestloc, "has the highest accuracy of", best)
  return best

def bestaccuracyNN():
  best = 0
  bestloc = -1
  for i in range(10):
    accuracy = getaverageaccuracyNN(uniquelocations[i])
    if accuracy > best:
      best = accuracy
      bestloc = i
  
  print("Location", bestloc, "has the highest accuracy of", best)
  return best

print(bestaccuracyLR())

bestaccuracyKNN()

bestaccuracyNN()